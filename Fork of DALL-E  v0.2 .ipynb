{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eE9Il-LxbVBG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/glide-text2im\n",
            "  Cloning https://github.com/openai/glide-text2im to /private/var/folders/lw/nnzcftr10z96sn1fbz37dkg80000gn/T/pip-req-build-orwz4ha2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/glide-text2im /private/var/folders/lw/nnzcftr10z96sn1fbz37dkg80000gn/T/pip-req-build-orwz4ha2\n",
            "  Resolved https://github.com/openai/glide-text2im to commit 9cc8e563851bd38f5ddb3e305127192cb0f02f5c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting Pillow\n",
            "  Downloading Pillow-9.0.1-cp38-cp38-macosx_10_10_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
            "\u001b[?25hCollecting attrs\n",
            "  Using cached attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "Collecting torch\n",
            "  Downloading torch-1.10.2-cp38-none-macosx_10_9_x86_64.whl (147.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.2/147.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
            "Collecting requests\n",
            "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex\n",
            "  Using cached regex-2022.1.18-cp38-cp38-macosx_10_9_x86_64.whl (288 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages (from ftfy->glide-text2im==0.0.0) (0.2.5)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages (from torch->glide-text2im==0.0.0) (4.0.1)\n",
            "Building wheels for collected packages: glide-text2im\n",
            "  Building wheel for glide-text2im (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for glide-text2im: filename=glide_text2im-0.0.0-py3-none-any.whl size=1953648 sha256=185f5caba152fb6643fec926c49526d96121c57c2abd59da79a7957b2ba0ea2c\n",
            "  Stored in directory: /private/var/folders/lw/nnzcftr10z96sn1fbz37dkg80000gn/T/pip-ephem-wheel-cache-n9w679v2/wheels/5c/d0/35/5737920d51cf7404c477d2de30909e3cc5e7e1236f5026cc05\n",
            "Successfully built glide-text2im\n",
            "Installing collected packages: regex, certifi, urllib3, tqdm, torch, Pillow, idna, ftfy, filelock, charset-normalizer, attrs, requests, glide-text2im\n",
            "Successfully installed Pillow-9.0.1 attrs-21.4.0 certifi-2021.10.8 charset-normalizer-2.0.12 filelock-3.4.2 ftfy-6.1.1 glide-text2im-0.0.0 idna-3.3 regex-2022.1.18 requests-2.27.1 torch-1.10.2 tqdm-4.62.3 urllib3-1.26.8\n"
          ]
        }
      ],
      "source": [
        "# Run this line in Colab to install the package if it is\n",
        "# not already installed.\n",
        "!pip install git+https://github.com/openai/glide-text2im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iA0QGuqIbVBI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/torch/package/_directory_reader.py:17: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:68.)\n",
            "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/flames/Library/Mobile Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork of DALL-E .ipynb Cell 2'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flames/Library/Mobile%20Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork%20of%20DALL-E%20.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mth\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flames/Library/Mobile%20Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork%20of%20DALL-E%20.ipynb#ch0000002?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglide_text2im\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownload\u001b[39;00m \u001b[39mimport\u001b[39;00m load_checkpoint\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/flames/Library/Mobile%20Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork%20of%20DALL-E%20.ipynb#ch0000002?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglide_text2im\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_creation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flames/Library/Mobile%20Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork%20of%20DALL-E%20.ipynb#ch0000002?line=6'>7</a>\u001b[0m     create_model_and_diffusion,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flames/Library/Mobile%20Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork%20of%20DALL-E%20.ipynb#ch0000002?line=7'>8</a>\u001b[0m     model_and_diffusion_defaults,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/flames/Library/Mobile%20Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork%20of%20DALL-E%20.ipynb#ch0000002?line=8'>9</a>\u001b[0m     model_and_diffusion_defaults_upsampler\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/flames/Library/Mobile%20Documents/com~apple~CloudDocs/Programming/Python3.0x/Fork%20of%20DALL-E%20.ipynb#ch0000002?line=9'>10</a>\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglide_text2im\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgaussian_diffusion\u001b[39;00m \u001b[39mimport\u001b[39;00m get_named_beta_schedule\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglide_text2im\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrespace\u001b[39;00m \u001b[39mimport\u001b[39;00m SpacedDiffusion, space_timesteps\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglide_text2im\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext2im_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=3'>4</a>\u001b[0m     InpaintText2ImUNet,\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=4'>5</a>\u001b[0m     SuperResInpaintText2ImUnet,\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=5'>6</a>\u001b[0m     SuperResText2ImUNet,\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=6'>7</a>\u001b[0m     Text2ImUNet,\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/model_creation.py?line=7'>8</a>\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py?line=0'>1</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py?line=1'>2</a>\u001b[0m \u001b[39mSimplified from https://github.com/openai/guided-diffusion/blob/main/guided_diffusion/gaussian_diffusion.py.\u001b[39;00m\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py?line=2'>3</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m----> <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mth\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/local/Caskroom/miniforge/base/envs/pytorch_m1/lib/python3.8/site-packages/glide_text2im/gaussian_diffusion.py?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_warmup_beta\u001b[39m(beta_start, beta_end, num_diffusion_timesteps, warmup_frac):\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import torch as th\n",
        "\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import (\n",
        "    create_model_and_diffusion,\n",
        "    model_and_diffusion_defaults,\n",
        "    model_and_diffusion_defaults_upsampler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp9JTO-RbVBJ"
      },
      "outputs": [],
      "source": [
        "# This notebook supports both CPU and GPU.\n",
        "# On CPU, generating one sample may take on the order of 20 minutes.\n",
        "# On a GPU, it should be under a minute.\n",
        "\n",
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY9pg9ajbVBJ"
      },
      "outputs": [],
      "source": [
        "# Create base model.\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "model.to(device)\n",
        "model.load_state_dict(load_checkpoint('base', device))\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQdunMM6bVBK"
      },
      "outputs": [],
      "source": [
        "# Create upsampler model.\n",
        "options_up = model_and_diffusion_defaults_upsampler()\n",
        "options_up['use_fp16'] = has_cuda\n",
        "options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling\n",
        "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
        "model_up.eval()\n",
        "if has_cuda:\n",
        "    model_up.convert_to_fp16()\n",
        "model_up.to(device)\n",
        "model_up.load_state_dict(load_checkpoint('upsample', device))\n",
        "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nRlkvWtbVBK"
      },
      "outputs": [],
      "source": [
        "def show_images(batch: th.Tensor):\n",
        "    \"\"\" Display a batch of images inline. \"\"\"\n",
        "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "    display(Image.fromarray(reshaped.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35LXTc9vbVBL"
      },
      "outputs": [],
      "source": [
        "# Sampling parameters\n",
        "prompt = \"an oil painting of a corgi\"\n",
        "batch_size = 1\n",
        "guidance_scale = 3.0\n",
        "\n",
        "# Tune this parameter to control the sharpness of 256x256 images.\n",
        "# A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
        "upsample_temp = 0.997"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj86A_kbbVBM"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Sample from the base model #\n",
        "##############################\n",
        "\n",
        "# Create the text tokens to feed to the model.\n",
        "tokens = model.tokenizer.encode(prompt)\n",
        "tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the classifier-free guidance tokens (empty)\n",
        "full_batch_size = batch_size * 2\n",
        "uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    [], options['text_ctx']\n",
        ")\n",
        "\n",
        "# Pack the tokens together into model kwargs.\n",
        "model_kwargs = dict(\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size + [uncond_mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Create a classifier-free guidance sampling function\n",
        "def model_fn(x_t, ts, **kwargs):\n",
        "    half = x_t[: len(x_t) // 2]\n",
        "    combined = th.cat([half, half], dim=0)\n",
        "    model_out = model(combined, ts, **kwargs)\n",
        "    eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "    cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "    half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
        "    eps = th.cat([half_eps, half_eps], dim=0)\n",
        "    return th.cat([eps, rest], dim=1)\n",
        "\n",
        "# Sample from the base model.\n",
        "model.del_cache()\n",
        "samples = diffusion.p_sample_loop(\n",
        "    model_fn,\n",
        "    (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq2WVuvPbVBN"
      },
      "outputs": [],
      "source": [
        "##############################\n",
        "# Upsample the 64x64 samples #\n",
        "##############################\n",
        "\n",
        "tokens = model_up.tokenizer.encode(prompt)\n",
        "tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options_up['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the model conditioning dict.\n",
        "model_kwargs = dict(\n",
        "    # Low-res image to upsample.\n",
        "    low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "    # Text tokens\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Sample from the base model.\n",
        "model_up.del_cache()\n",
        "up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
        "up_samples = diffusion_up.ddim_sample_loop(\n",
        "    model_up,\n",
        "    up_shape,\n",
        "    noise=th.randn(up_shape, device=device) * upsample_temp,\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model_up.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(up_samples)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Flames Co. DALLL-E 2.0x",
      "provenance": []
    },
    "interpreter": {
      "hash": "e7d6e62d90e7e85f9a0faa7f0b1d576302d7ae6108e9fe361594f8e1c8b05781"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
